{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as seabornInstance \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "import statsmodels.api as sm\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.svm import SVR\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Food_Supply_Quantity_kg_dataset = pd.read_csv('Food_Supply_Quantity_kg_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Alcoholic Beverages</th>\n",
       "      <th>Animal fats</th>\n",
       "      <th>Animal Products</th>\n",
       "      <th>Aquatic Products, Other</th>\n",
       "      <th>Cereals - Excluding Beer</th>\n",
       "      <th>Eggs</th>\n",
       "      <th>Fish, Seafood</th>\n",
       "      <th>Fruits - Excluding Wine</th>\n",
       "      <th>Meat</th>\n",
       "      <th>...</th>\n",
       "      <th>Vegetables</th>\n",
       "      <th>Vegetal Products</th>\n",
       "      <th>Obesity</th>\n",
       "      <th>Undernourished</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>Active</th>\n",
       "      <th>Population</th>\n",
       "      <th>Unit (all except Population)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.1973</td>\n",
       "      <td>9.4341</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>24.8097</td>\n",
       "      <td>0.2099</td>\n",
       "      <td>0.0350</td>\n",
       "      <td>5.3495</td>\n",
       "      <td>1.2020</td>\n",
       "      <td>...</td>\n",
       "      <td>6.7642</td>\n",
       "      <td>40.5645</td>\n",
       "      <td>4.5</td>\n",
       "      <td>29.8</td>\n",
       "      <td>0.005707</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>0.004855</td>\n",
       "      <td>38042000.0</td>\n",
       "      <td>%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1.6719</td>\n",
       "      <td>0.1357</td>\n",
       "      <td>18.7684</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5.7817</td>\n",
       "      <td>0.5815</td>\n",
       "      <td>0.2126</td>\n",
       "      <td>6.7861</td>\n",
       "      <td>1.8845</td>\n",
       "      <td>...</td>\n",
       "      <td>11.7753</td>\n",
       "      <td>31.2304</td>\n",
       "      <td>22.3</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.027047</td>\n",
       "      <td>0.001085</td>\n",
       "      <td>0.016445</td>\n",
       "      <td>0.009517</td>\n",
       "      <td>2858000.0</td>\n",
       "      <td>%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>0.2711</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>9.6334</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>13.6816</td>\n",
       "      <td>0.5277</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>6.3801</td>\n",
       "      <td>1.1305</td>\n",
       "      <td>...</td>\n",
       "      <td>11.6484</td>\n",
       "      <td>40.3651</td>\n",
       "      <td>26.6</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.009229</td>\n",
       "      <td>0.001037</td>\n",
       "      <td>0.004099</td>\n",
       "      <td>0.004094</td>\n",
       "      <td>43406000.0</td>\n",
       "      <td>%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Angola</td>\n",
       "      <td>5.8087</td>\n",
       "      <td>0.0560</td>\n",
       "      <td>4.9278</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>9.1085</td>\n",
       "      <td>0.0587</td>\n",
       "      <td>1.7707</td>\n",
       "      <td>6.0005</td>\n",
       "      <td>2.0571</td>\n",
       "      <td>...</td>\n",
       "      <td>2.3041</td>\n",
       "      <td>45.0722</td>\n",
       "      <td>6.8</td>\n",
       "      <td>25</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>31427000.0</td>\n",
       "      <td>%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Antigua and Barbuda</td>\n",
       "      <td>3.5764</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>16.6613</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5.9960</td>\n",
       "      <td>0.2274</td>\n",
       "      <td>4.1489</td>\n",
       "      <td>10.7451</td>\n",
       "      <td>5.6888</td>\n",
       "      <td>...</td>\n",
       "      <td>5.4495</td>\n",
       "      <td>33.3233</td>\n",
       "      <td>19.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024742</td>\n",
       "      <td>0.003093</td>\n",
       "      <td>0.011340</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>97000.0</td>\n",
       "      <td>%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>Venezuela (Bolivarian Republic of)</td>\n",
       "      <td>2.5952</td>\n",
       "      <td>0.0403</td>\n",
       "      <td>14.7565</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>12.9253</td>\n",
       "      <td>0.3389</td>\n",
       "      <td>0.9456</td>\n",
       "      <td>7.6460</td>\n",
       "      <td>3.8328</td>\n",
       "      <td>...</td>\n",
       "      <td>4.1474</td>\n",
       "      <td>35.2416</td>\n",
       "      <td>25.2</td>\n",
       "      <td>21.2</td>\n",
       "      <td>0.001168</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>28516000.0</td>\n",
       "      <td>%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>Vietnam</td>\n",
       "      <td>1.4591</td>\n",
       "      <td>0.1640</td>\n",
       "      <td>8.5765</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>16.8740</td>\n",
       "      <td>0.3077</td>\n",
       "      <td>2.6392</td>\n",
       "      <td>5.9029</td>\n",
       "      <td>4.4382</td>\n",
       "      <td>...</td>\n",
       "      <td>11.9508</td>\n",
       "      <td>41.4232</td>\n",
       "      <td>2.1</td>\n",
       "      <td>9.3</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>95656000.0</td>\n",
       "      <td>%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>Yemen</td>\n",
       "      <td>0.0364</td>\n",
       "      <td>0.0446</td>\n",
       "      <td>5.7874</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>27.2077</td>\n",
       "      <td>0.2579</td>\n",
       "      <td>0.5240</td>\n",
       "      <td>5.1344</td>\n",
       "      <td>2.7871</td>\n",
       "      <td>...</td>\n",
       "      <td>3.2135</td>\n",
       "      <td>44.2126</td>\n",
       "      <td>14.1</td>\n",
       "      <td>38.9</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>29162000.0</td>\n",
       "      <td>%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>5.7360</td>\n",
       "      <td>0.0829</td>\n",
       "      <td>6.0197</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>21.1938</td>\n",
       "      <td>0.3399</td>\n",
       "      <td>1.6924</td>\n",
       "      <td>1.0183</td>\n",
       "      <td>1.8427</td>\n",
       "      <td>...</td>\n",
       "      <td>3.4649</td>\n",
       "      <td>43.9789</td>\n",
       "      <td>6.5</td>\n",
       "      <td>46.7</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>17861000.0</td>\n",
       "      <td>%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>4.0552</td>\n",
       "      <td>0.0755</td>\n",
       "      <td>8.1489</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>22.6240</td>\n",
       "      <td>0.2678</td>\n",
       "      <td>0.5518</td>\n",
       "      <td>2.2000</td>\n",
       "      <td>2.6142</td>\n",
       "      <td>...</td>\n",
       "      <td>2.3213</td>\n",
       "      <td>41.8526</td>\n",
       "      <td>12.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>14645000.0</td>\n",
       "      <td>%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Country  Alcoholic Beverages  Animal fats  \\\n",
       "0                           Afghanistan               0.0014       0.1973   \n",
       "1                               Albania               1.6719       0.1357   \n",
       "2                               Algeria               0.2711       0.0282   \n",
       "3                                Angola               5.8087       0.0560   \n",
       "4                   Antigua and Barbuda               3.5764       0.0087   \n",
       "..                                  ...                  ...          ...   \n",
       "165  Venezuela (Bolivarian Republic of)               2.5952       0.0403   \n",
       "166                             Vietnam               1.4591       0.1640   \n",
       "167                               Yemen               0.0364       0.0446   \n",
       "168                              Zambia               5.7360       0.0829   \n",
       "169                            Zimbabwe               4.0552       0.0755   \n",
       "\n",
       "     Animal Products  Aquatic Products, Other  Cereals - Excluding Beer  \\\n",
       "0             9.4341                   0.0000                   24.8097   \n",
       "1            18.7684                   0.0000                    5.7817   \n",
       "2             9.6334                   0.0000                   13.6816   \n",
       "3             4.9278                   0.0000                    9.1085   \n",
       "4            16.6613                   0.0000                    5.9960   \n",
       "..               ...                      ...                       ...   \n",
       "165          14.7565                   0.0000                   12.9253   \n",
       "166           8.5765                   0.0042                   16.8740   \n",
       "167           5.7874                   0.0000                   27.2077   \n",
       "168           6.0197                   0.0000                   21.1938   \n",
       "169           8.1489                   0.0000                   22.6240   \n",
       "\n",
       "       Eggs  Fish, Seafood  Fruits - Excluding Wine    Meat  ...  Vegetables  \\\n",
       "0    0.2099         0.0350                   5.3495  1.2020  ...      6.7642   \n",
       "1    0.5815         0.2126                   6.7861  1.8845  ...     11.7753   \n",
       "2    0.5277         0.2416                   6.3801  1.1305  ...     11.6484   \n",
       "3    0.0587         1.7707                   6.0005  2.0571  ...      2.3041   \n",
       "4    0.2274         4.1489                  10.7451  5.6888  ...      5.4495   \n",
       "..      ...            ...                      ...     ...  ...         ...   \n",
       "165  0.3389         0.9456                   7.6460  3.8328  ...      4.1474   \n",
       "166  0.3077         2.6392                   5.9029  4.4382  ...     11.9508   \n",
       "167  0.2579         0.5240                   5.1344  2.7871  ...      3.2135   \n",
       "168  0.3399         1.6924                   1.0183  1.8427  ...      3.4649   \n",
       "169  0.2678         0.5518                   2.2000  2.6142  ...      2.3213   \n",
       "\n",
       "     Vegetal Products  Obesity  Undernourished  Confirmed    Deaths  \\\n",
       "0             40.5645      4.5            29.8   0.005707  0.000168   \n",
       "1             31.2304     22.3             6.2   0.027047  0.001085   \n",
       "2             40.3651     26.6             3.9   0.009229  0.001037   \n",
       "3             45.0722      6.8              25   0.000086  0.000006   \n",
       "4             33.3233     19.1               0   0.024742  0.003093   \n",
       "..                ...      ...             ...        ...       ...   \n",
       "165           35.2416     25.2            21.2   0.001168  0.000056   \n",
       "166           41.4232      2.1             9.3   0.000282  0.000000   \n",
       "167           44.2126     14.1            38.9   0.000021  0.000007   \n",
       "168           43.9789      6.5            46.7   0.000593  0.000017   \n",
       "169           41.8526     12.3            51.3   0.000273  0.000027   \n",
       "\n",
       "     Recovered    Active  Population  Unit (all except Population)  \n",
       "0     0.000683  0.004855  38042000.0                             %  \n",
       "1     0.016445  0.009517   2858000.0                             %  \n",
       "2     0.004099  0.004094  43406000.0                             %  \n",
       "3     0.000022  0.000057  31427000.0                             %  \n",
       "4     0.011340  0.010309     97000.0                             %  \n",
       "..         ...       ...         ...                           ...  \n",
       "165   0.000498  0.000614  28516000.0                             %  \n",
       "166   0.000229  0.000053  95656000.0                             %  \n",
       "167   0.000003  0.000010  29162000.0                             %  \n",
       "168   0.000308  0.000269  17861000.0                             %  \n",
       "169   0.000034  0.000212  14645000.0                             %  \n",
       "\n",
       "[170 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Food_Supply_Quantity_kg_data = Food_Supply_Quantity_kg_dataset.fillna(0)\n",
    "Food_Supply_Quantity_kg = Food_Supply_Quantity_kg_data.replace(\"<2.5\", 2.5)\n",
    "Food_Supply_Quantity_kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Food_Supply_Quantity_kg[['Alcoholic Beverages', 'Animal fats', 'Animal Products', 'Aquatic Products, Other', 'Cereals - Excluding Beer', 'Eggs', 'Fish, Seafood', 'Fruits - Excluding Wine', 'Meat', 'Milk - Excluding Butter','Miscellaneous','Offals','Oilcrops','Pulses','Spices','Starchy Roots','Stimulants','Sugar & Sweeteners','Sugar Crops','Treenuts','Vegetable Oils','Vegetables','Vegetal Products','Obesity','Population']]\n",
    "\n",
    "y = Food_Supply_Quantity_kg['Deaths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-9.90798177849743\n",
      "-15.47381146049804\n"
     ]
    }
   ],
   "source": [
    "# Train the model using the training sets and check score on test dataset\n",
    "svr = SVR()\n",
    "svr.fit(X_train, y_train)\n",
    "print(svr.score(X_train, y_train))\n",
    "print(svr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr.fit(X_train, y_train)\n",
    "predicted= svr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "... on training data [0.03313842 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842\n",
      " 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842\n",
      " 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842\n",
      " 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842\n",
      " 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842\n",
      " 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842\n",
      " 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842\n",
      " 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842\n",
      " 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842\n",
      " 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842\n",
      " 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842\n",
      " 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842\n",
      " 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842\n",
      " 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842\n",
      " 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842\n",
      " 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842\n",
      " 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842\n",
      " 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842\n",
      " 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842\n",
      " 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842\n",
      " 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842\n",
      " 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842\n",
      " 0.03313842 0.03313842 0.03313842 0.03313842]\n",
      "\n",
      "RMSE on train dataset :  0.031332745478818994\n",
      "\n",
      "... on test data [0.03313842 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842\n",
      " 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842\n",
      " 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842\n",
      " 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842\n",
      " 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842 0.03313842\n",
      " 0.03313842 0.03313842 0.03313842 0.03313842]\n",
      "\n",
      "RMSE on test dataset :  0.03148483207774258\n"
     ]
    }
   ],
   "source": [
    "# predict the target on the test dataset\n",
    "predict_train_svr = svr.predict(X_train)\n",
    "print('\\n... on training data',predict_train_svr) \n",
    "\n",
    "# Root Mean Squared Error on training dataset\n",
    "rmse_train = mean_squared_error(y_train,predict_train_svr)**(0.5)\n",
    "print('\\nRMSE on train dataset : ', rmse_train)\n",
    "\n",
    "# predict the target on the testing dataset\n",
    "predict_test_svr = svr.predict(X_test)\n",
    "print('\\n... on test data',predict_test_svr) \n",
    "\n",
    "# Root Mean Squared Error on testing dataset\n",
    "rmse_test = mean_squared_error(y_test,predict_test_svr)**(0.5)\n",
    "print('\\nRMSE on test dataset : ', rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.031332745478818994\n",
      "-9.90798177849743\n",
      "0.03148483207774258\n",
      "-15.473811460498041\n"
     ]
    }
   ],
   "source": [
    "pred_train_svr= svr.predict(X_train)\n",
    "print(np.sqrt(mean_squared_error(y_train,pred_train_svr)))\n",
    "print(r2_score(y_train, pred_train_svr))\n",
    "\n",
    "pred_test_svr= svr.predict(X_test)\n",
    "print(np.sqrt(mean_squared_error(y_test,pred_test_svr))) \n",
    "print(r2_score(y_test, pred_test_svr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required packages\n",
    "from sklearn import neighbors\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE value for k=  1 is: 0.009374390433100876\n",
      "RMSE value for k=  2 is: 0.008960129135994106\n",
      "RMSE value for k=  3 is: 0.00813779633154126\n",
      "RMSE value for k=  4 is: 0.007609301839610389\n",
      "RMSE value for k=  5 is: 0.007821779051203792\n",
      "RMSE value for k=  6 is: 0.007896931160414823\n",
      "RMSE value for k=  7 is: 0.006978603310329463\n",
      "RMSE value for k=  8 is: 0.007080352785708506\n",
      "RMSE value for k=  9 is: 0.007268227917357725\n",
      "RMSE value for k=  10 is: 0.007366369325960088\n",
      "RMSE value for k=  11 is: 0.007567912404808761\n",
      "RMSE value for k=  12 is: 0.0077055147443909925\n",
      "RMSE value for k=  13 is: 0.007903696286558765\n",
      "RMSE value for k=  14 is: 0.00793624494682378\n",
      "RMSE value for k=  15 is: 0.007938747306126698\n",
      "RMSE value for k=  16 is: 0.00777680723614515\n",
      "RMSE value for k=  17 is: 0.007808679705840086\n",
      "RMSE value for k=  18 is: 0.007818676970321072\n",
      "RMSE value for k=  19 is: 0.007798796886311141\n",
      "RMSE value for k=  20 is: 0.007911078676661161\n",
      "RMSE value for k=  21 is: 0.007849251721520806\n",
      "RMSE value for k=  22 is: 0.007802721416309467\n",
      "RMSE value for k=  23 is: 0.0077861226054118035\n",
      "RMSE value for k=  24 is: 0.007676133597328695\n",
      "RMSE value for k=  25 is: 0.007628288257362833\n",
      "RMSE value for k=  26 is: 0.00761518426526973\n",
      "RMSE value for k=  27 is: 0.007610317436397204\n",
      "RMSE value for k=  28 is: 0.007606395374653091\n",
      "RMSE value for k=  29 is: 0.007657931807125237\n",
      "RMSE value for k=  30 is: 0.007659775617537771\n",
      "RMSE value for k=  31 is: 0.00766924241610756\n",
      "RMSE value for k=  32 is: 0.0076661696116428115\n",
      "RMSE value for k=  33 is: 0.007662693722011889\n",
      "RMSE value for k=  34 is: 0.007685925877417593\n",
      "RMSE value for k=  35 is: 0.00764583088551905\n",
      "RMSE value for k=  36 is: 0.007631832182352408\n",
      "RMSE value for k=  37 is: 0.0076292972660047306\n",
      "RMSE value for k=  38 is: 0.007628122284177715\n",
      "RMSE value for k=  39 is: 0.007632994466844258\n",
      "RMSE value for k=  40 is: 0.007693281437680058\n",
      "RMSE value for k=  41 is: 0.00767787310454403\n",
      "RMSE value for k=  42 is: 0.007686282115322216\n",
      "RMSE value for k=  43 is: 0.007692043420531956\n",
      "RMSE value for k=  44 is: 0.007709972280613926\n",
      "RMSE value for k=  45 is: 0.007709369933416121\n",
      "RMSE value for k=  46 is: 0.0076763413311441\n",
      "RMSE value for k=  47 is: 0.007684578261955041\n",
      "RMSE value for k=  48 is: 0.007686221403960717\n",
      "RMSE value for k=  49 is: 0.0077294308646307765\n",
      "RMSE value for k=  50 is: 0.007737984403446786\n",
      "RMSE value for k=  51 is: 0.00779600283694424\n",
      "RMSE value for k=  52 is: 0.0077930955759988665\n",
      "RMSE value for k=  53 is: 0.0077912427877632464\n",
      "RMSE value for k=  54 is: 0.007602879873483746\n",
      "RMSE value for k=  55 is: 0.007606299736679411\n",
      "RMSE value for k=  56 is: 0.007587498249644458\n",
      "RMSE value for k=  57 is: 0.007626850697882209\n",
      "RMSE value for k=  58 is: 0.007633978029624852\n",
      "RMSE value for k=  59 is: 0.007639622377003757\n",
      "RMSE value for k=  60 is: 0.007593585591921989\n",
      "RMSE value for k=  61 is: 0.00757787022031621\n",
      "RMSE value for k=  62 is: 0.007616850025917538\n",
      "RMSE value for k=  63 is: 0.007630377244373365\n",
      "RMSE value for k=  64 is: 0.007641297845536365\n",
      "RMSE value for k=  65 is: 0.007659096023381193\n",
      "RMSE value for k=  66 is: 0.007654144056260535\n",
      "RMSE value for k=  67 is: 0.007619748315531735\n",
      "RMSE value for k=  68 is: 0.00763308499523759\n",
      "RMSE value for k=  69 is: 0.007662530081767334\n",
      "RMSE value for k=  70 is: 0.007663976331975312\n",
      "RMSE value for k=  71 is: 0.00766540171128995\n",
      "RMSE value for k=  72 is: 0.0076699164828902796\n",
      "RMSE value for k=  73 is: 0.0076758583796985485\n",
      "RMSE value for k=  74 is: 0.007681281265853595\n",
      "RMSE value for k=  75 is: 0.007758882813912314\n",
      "RMSE value for k=  76 is: 0.0077474422980528205\n",
      "RMSE value for k=  77 is: 0.007745141995490722\n",
      "RMSE value for k=  78 is: 0.007741092173037638\n",
      "RMSE value for k=  79 is: 0.007743459451580516\n",
      "RMSE value for k=  80 is: 0.007744575413477119\n",
      "RMSE value for k=  81 is: 0.007737781217422838\n",
      "RMSE value for k=  82 is: 0.007697547043389782\n",
      "RMSE value for k=  83 is: 0.007706556731923978\n",
      "RMSE value for k=  84 is: 0.007703180180278061\n",
      "RMSE value for k=  85 is: 0.00770645495807499\n",
      "RMSE value for k=  86 is: 0.007699644175945299\n",
      "RMSE value for k=  87 is: 0.007704629443253201\n",
      "RMSE value for k=  88 is: 0.007704321945064399\n",
      "RMSE value for k=  89 is: 0.00768438102933238\n",
      "RMSE value for k=  90 is: 0.007692287994737211\n",
      "RMSE value for k=  91 is: 0.0076912390755105\n",
      "RMSE value for k=  92 is: 0.007690370158322881\n",
      "RMSE value for k=  93 is: 0.007688740572529026\n",
      "RMSE value for k=  94 is: 0.007685102963974845\n",
      "RMSE value for k=  95 is: 0.0076800118855267175\n",
      "RMSE value for k=  96 is: 0.007680791194365654\n",
      "RMSE value for k=  97 is: 0.007683560694630064\n",
      "RMSE value for k=  98 is: 0.00768423047080226\n",
      "RMSE value for k=  99 is: 0.007684067847932823\n",
      "RMSE value for k=  100 is: 0.007678459915063618\n"
     ]
    }
   ],
   "source": [
    "rmse_val = [] #to store rmse values for different k\n",
    "for K in range(100):\n",
    "    K = K+1\n",
    "    model = neighbors.KNeighborsRegressor(n_neighbors = K)\n",
    "\n",
    "    model.fit(X_train, y_train)  #fit the model\n",
    "    pred=model.predict(X_test) #make prediction on test set\n",
    "    error = sqrt(mean_squared_error(y_test,pred)) #calculate rmse\n",
    "    rmse_val.append(error) #store rmse values\n",
    "    print('RMSE value for k= ' , K , 'is:', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x24ad4772fc8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting the rmse values against k values\n",
    "curve = pd.DataFrame(rmse_val) #elbow curve \n",
    "curve.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007678459915063618"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = mean_squared_error(y_test, pred)\n",
    "rmse = np.sqrt(mse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.00403 degrees.\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - y_test)\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 5), 'degrees.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_knn = neighbors.KNeighborsRegressor(n_neighbors = 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE value for k=  27 is: 0.007610317436397204\n"
     ]
    }
   ],
   "source": [
    "model_knn.fit(X_train, y_train)  #fit the model\n",
    "pred=model_knn.predict(X_test) #make prediction on test set\n",
    "error = sqrt(mean_squared_error(y_test,pred)) #calculate rmse\n",
    "print('RMSE value for k= ' , 27 , 'is:', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat([y_train, X_train], axis=1)\n",
    "test_data = pd.concat([y_test, X_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "       n_clusters=8, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "       random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KMeans()  \n",
    "\n",
    "# fit the model with the training data\n",
    "model.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Default number of Clusters :  8\n"
     ]
    }
   ],
   "source": [
    "# Number of Clusters\n",
    "print('\\nDefault number of Clusters : ',model.n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CLusters on train data [6 4 5 1 4 5 4 4 5 4 4 4 4 4 2 1 4 0 1 2 4 1 4 4 1 1 4 4 4 5 4 4 4 4 4 2 4\n",
      " 5 1 7 4 3 1 1 4 4 1 4 4 1 5 4 4 1 4 1 1 1 4 4 4 4 4 5 4 4 4 1 1 5 4 5 5 1\n",
      " 5 4 4 4 4 1 4 1 1 3 3 4 4 4 4 4 4 4 4 7 4 4 4 4 4 4 4 1 5 4 4 4 1 4 1 4 3\n",
      " 4 4 1 4 4 4 5 4 4 5 4 4 1 4 4 4 5 3 1 7 5 4 4 1 4]\n"
     ]
    }
   ],
   "source": [
    "# predict the clusters on the train dataset\n",
    "predict_train = model.predict(train_data)\n",
    "print('\\nCLusters on train data',predict_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters on test data [4 0 4 1 4 1 3 5 5 1 4 4 4 4 0 4 1 4 4 1 4 4 5 4 4 4 5 4 2 4 4 3 4 4]\n"
     ]
    }
   ],
   "source": [
    "# predict the target on the test dataset\n",
    "predict_test = model.predict(test_data)\n",
    "print('Clusters on test data',predict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Clusters :  3\n",
      "\n",
      "CLusters on train data [1 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 1 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0\n",
      " 0 0 1 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 2 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2\n",
      " 0 0 0 0 0 0 2 0 0 2 0 0 0 0 0 0 2 2 0 1 0 0 0 0 0]\n",
      "Clusters on test data [0 1 0 0 0 0 2 2 2 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 2 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Now, we will train a model with n_cluster = 3\n",
    "model_n3 = KMeans(n_clusters=3)\n",
    "\n",
    "# fit the model with the training data\n",
    "model_n3.fit(train_data)\n",
    "\n",
    "# Number of Clusters\n",
    "print('\\nNumber of Clusters : ',model_n3.n_clusters)\n",
    "\n",
    "# predict the clusters on the train dataset\n",
    "predict_train_3 = model_n3.predict(train_data)\n",
    "print('\\nCLusters on train data',predict_train_3) \n",
    "\n",
    "# predict the target on the test dataset\n",
    "predict_test_3 = model_n3.predict(test_data)\n",
    "print('Clusters on test data',predict_test_3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
